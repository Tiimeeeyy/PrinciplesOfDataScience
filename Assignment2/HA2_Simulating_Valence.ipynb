{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sev3wtZP0Ipc"
   },
   "source": [
    "# KEN1435 - Principles of Data Science | Homework Assignment 2 (HA1) :  Simulating Sentiment\n",
    "\n",
    "In this assignment, you will take a look at the distribution of sentiment as observed in the Brown corpus. Using the observed distribution of sentiment, you will simulate new messages with corresponding sentiment and compare this new distribution with the observed one.\n",
    "\n",
    "First we load the necessary python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ak2gYqYjZlmI"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "\n",
    "tab10 = plt.get_cmap(\"tab10\").colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxTWG57e0qs1"
   },
   "source": [
    "## Sentiment distribution in the Brown corpus. \n",
    "For this assignment, we will use the Brown corpus. This corpus is contained in the package `nltk`. As working with sentiment analysis is not part of this course, we are giving you a preprocessed data set. \n",
    "\n",
    "### Exercise 1. (*1pt*)\n",
    "Load the data set as provided in the file `ANEW_Valence_per_word.tsv` into the variable `per_word`.\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kH140bJp0wmA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2. (*2pt*)\n",
    "The score per document can be calculated as the average score of all observed words per document. Plot the distribution of the observed sentiment distribution for all documents (recall that we can observe values ranging from 1 to 9).\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3. (*2pt*)\n",
    "Plot the distribution of the number of words that are contained in the lexicon per document.\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4. (*2pt*)\n",
    "Plot the distribution of the observed sentiment distribution for all words (recall that we can observe values ranging from 1 to 9).\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating ANEW Valence\n",
    "Based on the distributions that we have visualized above, we can simulate the sentiment in new texts.\n",
    "\n",
    "### Exercise 5. (*2pt*)\n",
    "Simulate `10,000` new sentiment scores at the document level. Use the empirical distributions for both the word scores and the number of observed words in the lexicon for a document. Plot both the distribution of the simulated sentiment and the observed sentiment in a single figure.\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6. (*1pt*)\n",
    "Describe the differences between the distributions of the simulated and the real-world observations. Where is the difference the largest and what can this tell us about human language? \n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
